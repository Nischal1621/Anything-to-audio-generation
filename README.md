# Assistive System: Video-to-Audio & Image-to-Audio Generation

This project is designed to support visually impaired users by converting visual content into meaningful audio descriptions.

It includes:
- ğŸ¥ **Video-to-Audio**: Extract frames from video â†’ Recognize scenes/objects â†’ Convert to speech
- ğŸ–¼ **Image-to-Audio**: Detect the content in images â†’ Generate spoken feedback

This helps blind or low-vision users better understand surroundings by listening to audio information.

---

## âœ¨ Features

| Feature | Description |
|--------|-------------|
| Video Frame Extraction | Video is broken into key frames for interpretation |
| Object & Scene Recognition | AI model identifies objects, text, and context |
| Real-Time Audio Output | Text-to-speech conversion speaks detected content |
| Camera & Media Support | Supports webcam images or uploaded files |

---

## ğŸ”§ Technologies Used
- **PyTorch** â€” Deep learning framework
- **Transformers (HuggingFace)** â€” Vision models like ViT, BLIP, or DETR
- **OpenCV** â€” Video capture & frame extraction
- **Speech engines** â€” `pyttsx3` (offline) / `gTTS` (online)
- **SpeechRecognition & pydub** â€” Optional audio utilities

---

## ğŸ“ Project Workflow

### 1ï¸âƒ£ Image-to-Audio
